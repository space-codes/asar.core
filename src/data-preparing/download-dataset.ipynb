{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649588074117
    }
   },
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 1qGWokd9ghYj2braD0R1xzCxG4EmCWrvZ\n",
    "!gdown --id 1iu4OIdcheZFTw0-SehJVC18WU-U4oWeC\n",
    "!unzip asar-dataset-v2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Move test data into train, and val folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649626614501
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def list_splitter(list_to_split, ratio):\n",
    "    first_half = int(len(list_to_split) * ratio)\n",
    "    return list_to_split[:first_half], list_to_split[first_half:]\n",
    "\n",
    "source = os.path.join(os.getcwd(), 'asar-dataset-v2/test')\n",
    "target1 = os.path.join(os.getcwd(), 'asar-dataset-v2/train')\n",
    "target2 = os.path.join(os.getcwd(), 'asar-dataset-v2/val')\n",
    "\n",
    "list_dir = os.listdir(source)\n",
    "for sub_dir in list_dir:\n",
    "    print(\"moving \" + str(sub_dir))\n",
    "    target_val_folder = os.path.join(target2, sub_dir)\n",
    "    target_train_folder = os.path.join(target1, sub_dir)\n",
    "    if os.path.exists(target_val_folder) and os.path.exists(target_train_folder):\n",
    "        folderPath = os.path.join(source, sub_dir)\n",
    "        files = os.listdir(folderPath)\n",
    "        val_list, train_list = list_splitter(files, 0.5)\n",
    "        for filename in val_list:\n",
    "            filePath = os.path.join(folderPath, filename)\n",
    "            shutil.move(filePath, target_val_folder)\n",
    "        for filename in train_list:\n",
    "            filePath = os.path.join(folderPath, filename)\n",
    "            shutil.move(filePath, target_train_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean dataset misspelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Read erros.txt file in dict with old_value=key and new_value=value\n",
    "words_dict = {}\n",
    "file = open('errors.txt', 'r', encoding=\"UTF-8-sig\")\n",
    "Lines = file.readlines()\n",
    "\n",
    "for line in Lines:\n",
    "    words = line.strip().split(\"=>\")\n",
    "    words_dict[words[0].strip()]= words[1].strip()\n",
    "\n",
    "# Rename old_value with new_value with merging folder if exists\n",
    "\n",
    "folders = ['asar-dataset-v2/train', 'asar-dataset-v2/val']\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.getcwd() + '/' + folder\n",
    "    directories = os.listdir(folder_path)\n",
    "    for directory in directories:\n",
    "        if directory in words_dict.keys():\n",
    "            new_word = words_dict[directory]\n",
    "            old_word_path = folder_path + '/' + directory\n",
    "            new_word_path = folder_path + '/' + new_word\n",
    "            if os.path.exists(new_word_path):\n",
    "                # move files, delete this folder\n",
    "                images = os.listdir(old_word_path)\n",
    "                for image in images:\n",
    "                    if os.path.exists(new_word_path + '/' + image):\n",
    "                        file_name, ext = image.split(\"/\")[-1].split(\".\")\n",
    "                        r = random.randint(1, 1000)\n",
    "                        modified_image = os.path.join(new_word_path, f\"{file_name}_{r}.{ext}\")\n",
    "                        shutil.move(old_word_path + '/' + image, modified_image)\n",
    "                    else:\n",
    "                        shutil.move(old_word_path + '/' + image, new_word_path)\n",
    "                shutil.rmtree(old_word_path)\n",
    "                print(\"deleting \" + directory)\n",
    "            else:\n",
    "                # just rename it\n",
    "                print(\"renaming \" + directory)\n",
    "                os.rename(old_word_path, new_word_path)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
